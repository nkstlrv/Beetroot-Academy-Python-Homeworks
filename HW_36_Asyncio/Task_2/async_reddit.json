{"coroutine": {"clarketta": {"comment": "I think we should take turns doing it to a coroutine", "time": "2023-03-25 06:01:06"}, "yvrelna": {"comment": "You can write a decorator that wraps `async def` to automatically call `create_task` though.\n\n&gt; In JavaScript, it begins execution immediately\n\nThis is not quite true. In JavaScript, the coroutine is scheduled immediately and is ready to run as soon as it's called, but it won't actually run until the current function either terminates or hit an await statement.\n\nBasically, this will never terminate because setTrue will never start:\n\n    async function setTrue(obj) {\n        obj.result = true\n    }\n    async function foo() {\n        setTrue(obj)\n        while (!obj.result) {\n            console.log(\"not done yet\")\n        }\n    }", "time": "2023-03-25 04:23:13"}, "FerricDonkey": {"comment": "**Q1:** call `semaphore.release()`. Acquire reduces the count (waiting until one is available if necessary), release raises the count. Normally you use `with` as you are in your example to make sure that resources are released when you're done with them, but if you want to increase or reduce the pool directly then you can do so with acquire and release.\n\n**Q2:** Personally, at this point I'd swap away from semaphores and switch to workers and tasks, assuming your special teller also does regular tasks (otherwise just have multiple types of semaphores).\n\nMake a queue for regular tasks, a queue for special teller tasks. Make a coroutine that checks these queues in a loop for either a special task (if special teller), then for a regular task (if not special teller or if there are no regular tasks). To be absolutely safe, if checking the queues and pulling from them ends up being separate operations, guard queue checking and extraction behind a lock. Make sure to make it so that you have some way to stop the coroutines.\n\nThen use asyncio.create_task to start tellers (don't await the tellers, just start em), and have your main function manage putting tasks where they go, starting new teller coroutines or stopping existing ones as people come on and off duty, etc.\n\n**Q3:** Same as Q2, but make a manager coroutine that only monitors/prioritizes the manager queue.\n\nNote that if it's important things get done in the order they show up (eg, if you don't want your second customer to randomly have to wait for 85 people who came in behind him just from bad luck), then queues will be better than semaphore. \n\nSemaphores don't ensure that the first person to ask gets the resource first, only that the first you don't try to use the semaphore more than allowed.", "time": "2023-03-25 03:36:52"}, "bsenftner": {"comment": "I'm using FasAPI and testing various coroutine, and threading methods. I'm more experienced in multi-threading in C++ and finding the Python options to be quirky, poorly documented, only focused on I/O, and largely inappropriate for anything other than I/O - meaning actual compute requirements such as running an ML model halts everything. \n\nIt appears the Python ecosystem has a terminology problem, and are using the term \"threads\" too liberally, when they are not \"threads\" but co-operative multi-threading in the same manner that many GUI frameworks operate. I'm probably going to abandon Python's parallel code efforts simply because the terminology usage is too blurry, I have to actually implement and examine to figure out if it really is a thread, really is capable of not blocking other \"threads\" despite needing to spin-compute for durations as long as a few seconds. \n\nAchieving such in C++ is trivial, so I'm probably going to start cracking open C++/Python interoperability.", "time": "2023-03-24 12:53:25"}, "equeim": {"comment": "They use main thread's event loop (`Handler` with `Looper.getMainLooper()`) and background thread pool.\n\nWhen you start asynchronous operation your coroutine suspends (and returns control to event loop), and then some other thread (that for example does polling on tcp socket) resumes it on the main thread using `Handler.post()`. From caller perspective it works seamlessly, as if they never left main thread (of course implementation of this asynchronous operation will need to have some boilerplate code that does triggers resume and bridges callback/thread world with coroutine world. `suspendCancellableCoroutine` function is typically used for that).\n\nYou also can choose to resume your coroutine on background thread instead of main thread if you need to do some CPU-intensive calculations or blocking I/O. For that background threads in thread pool have their own event loops (to switch between threads/thread pools you pass `CoroutineDIspatcher`, typically from `Dispatchers` singleton, to `withContext` function).", "time": "2023-03-24 11:52:10"}}, "django": {"OmegaBrainNihari": {"comment": "Is it okay to be offended as a django developer", "time": "2023-03-25 07:53:14"}, "arzib": {"comment": "Reminds me of that one scene in Django", "time": "2023-03-25 07:43:40"}, "ramabrahma": {"comment": "OP should learn to save simple form data into a database and display database data on a page first before considering real time updates and cross browser support. However, Django.Channels can provide such real time support.\n\nTutorial: https://realpython.com/getting-started-with-django-channels/\n\nCan't do persistant CRUD with just React. You need to integrate the Express and Node frameworks for such tooling.\n\nDjango also has a User Auth system built in to handle logins and to provide roles based access. \n\nLol the best and preferred routes are still subjective to Python and JS fanboy preferences. But it's up to OP; their choice really we can only give our 2 cents.", "time": "2023-03-25 07:36:15"}, "midenginedcoupe": {"comment": "With respect, I think the market rate for what you\u2019re looking for is not what you think it is.\n\nIt sounds like the music you\u2019re looking for is far from niche and any jobbing function musos could do it in their sleep. Ask around and find out what a function band would charge and I don\u2019t think you\u2019ll like the answer.\n\nBut the advice elsewhere in this thread is good. You don\u2019t need a full quartet, let alone even more, it will be too loud for a small restaurant. See if the same money will get you one good musician who can do what you want. If you\u2019re after a Django Reinhardt feel then book a guitarist who knows that stuff inside out.\n\nIf you\u2019re only at the end of the market with people like the poster above who thinks jazz musicians only do it for the love and shouldn\u2019t be paid fairly, then you\u2019ll obviously only get half-assed amateurs and kids.", "time": "2023-03-25 07:33:54"}, "Master_Cupcake7115": {"comment": "Django Unchained, Inception, Get Out to name but a few.", "time": "2023-03-25 07:28:29"}}, "json": {"Mucksh": {"comment": "Don't think there is anything special with it. They just forgot to remove it from the release build. Probably there are also some other parts around already finished but just not added to it. There is also some left over LUA script that creates the part definitions of the interstellar ones. Transfered one into JSON but not sure what is the correct way to load it and also it seems that meanwhile they changed the format a little bit how the parts are stored", "time": "2023-03-25 08:12:09"}, "mrSemantix": {"comment": "Express server as serverless function from Netlify. \nBuild something where you host an express server as backend, perhaps a JSON with some products if you build a webshop, pull in the data in your frontend, if you got it all working locally, use netlify for hosting your backend.", "time": "2023-03-25 07:53:27"}, "totaltasch": {"comment": "Has anyone had success with Canadian outback? I am getting a hostname error for the execute.json url with [mysubaru.ca](https://mysubaru.ca) domain.", "time": "2023-03-25 07:48:22"}, "Sudneo": {"comment": "Onestamente, questo \u00e8 anche per un difetto nella logica con il quale i prodotti tech vengono progettati ed eseguiti.\n\nAvere applicazioni che richiedono sempre pi\u00f9 potenza (declinata come vogliamo: CPU, memoria, banda di rete, etc.) \u00e8 ridicolo, oltre che comunque discriminatorio, perch\u00e9 in ogni caso non \u00e8 che tutto il mondo avr\u00e0 il 5g ovunque, e anche ecologicamente criminale (pi\u00f9 emissioni per le computazione, trasferimenti dati, rimpiazzare hardware etc.).\n\nQuindi \u00e8 anche responsabilit\u00e0 dell'industria evitare che questo accada. E sto parlando di cose concrete eh, non astratte, cose come \"ottimizza il tuo cazzo di codice\" o \"non mi buttare 20MB di JSON per utilizzare 2 stringhe ogni richiesta al tuo sito\".", "time": "2023-03-25 07:41:54"}}, "event loop": {"A-bomb14": {"comment": "Hello. Pygame is a very nice module for something like this.\n\nInstalling external modules requires you to enter this command into the terminal\n\npip3 install \u201cmodule name\u201d\nOR\npip install \u201cmodule name\u201d (if the above doesn\u2019t work)\n\nSo in this case: pip3 install pygame\n\nThen in your code write at the top \u201cimport pygame\u201d.\n\n\nYou can set up a display window, import images, rotate images, and so much more.\n\nWhen working with computer graphics the origin is actually top left, for the display, images, etc. (saw this question on another comment) \n\nThe top answer on [this](https://stackoverflow.com/questions/4183208/how-do-i-rotate-an-image-around-its-center-using-pygame) thread will help with the wackiness of rotating (may need to import math)\n\nLearning pygame\u2019s functions might be hard but google can help you with everything and the pygame docs are nice.\n\nImportant parts of pygame\n\npygame.display.flip() \n\nUpdates the display\n\n\ndone = False\nwhile not done:\n    for event in pygame.event.get():\n        if event.type == pygame.QUIT:\n            done = True\n\nThis will be your main loop so you can constantly update and modify the graphics on screen. The event portion allows you to quit without an error.", "time": "2023-03-25 07:10:57"}, "AutoModerator": {"comment": "Your submission has been removed because it concerns, or has been prompted by, a recent or current event. Recent events are a topic not covered in ELI5 under rule 2.  It's possible posted about before, even if this is not the case. Please search the subreddit before posting. If this is about a recent/current event, please consider trying a sub such as /r/news, /r/worldnews, /r/OutOfTheLoop, or /r/NoStupidQuestions. Please make sure to read their rules and their current megathreads (if related).\n\n**If you believe this post was removed erroneously**, please [use this form](https://old.reddit.com/message/compose?to=%2Fr%2Fexplainlikeimfive&amp;subject=Can%20you%20review%20my%20thread?&amp;message=Link:%20/r/explainlikeimfive/comments/121dh6e/eli5_how_is_a_memory_stick_different_from_power/%0A%0APlease%20answer%20the%20following%203%20questions:%0A%0A1.%20The%20concept%20I%20want%20explained:%0A%0A2.%20List%20the%20search%20terms%20you%20used%20to%20look%20for%20past%20posts%20on%20ELI5:%0A%0A3.%20How%20is%20this%20post%20unique:) and we will review your submission. Note that **if you do not fill out the form completely**, your message **will not be reviewed**.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/explainlikeimfive) if you have any questions or concerns.*", "time": "2023-03-25 06:44:30"}, "4colour": {"comment": "Isn't this what is triggered after you call client.run(), which starts an event loop? This is exactly what I'm trying to get away from.", "time": "2023-03-25 06:24:25"}, "-Chaotique-": {"comment": "Ooo how exciting for you! Off the top of my head I would recommend \n\nI would print out some business cards if you're looking to expand your client base. \n\nBring a deck you don't mind getting manhandled a bit. If you don't have one already, buy a fairly inexpensive one. Be prepared for cards to accidentally get a bit dirty, wet, bent, or otherwise take some minor damage. Even if you don't allow others to touch your cards, if it's an outdoor event a gust of wind might blow them off the table or someone might bump your table and spill your tea or something onto your cards\n\nMake sure you stay very well hydrated, so keep a lot of water or tea on hand\n\nYou'll be doing a *lot* of talking, so make sure you have lozenges in case your throat begins to get sore\n\nBring snacks, take breaks and stretch when possible to keep your energy levels up\n\nWear comfortable clothing. Especially make sure you have layers you can put on or take off so you don't get too cold or too hot \n\nOccasionally, you might get someone who wants to test you. It's not as common at a metaphysical event, but often they're skeptics who are there with their partner who is interested in tarot. It's fine to humor them if you'd like, but make sure you have good boundaries and don't be afraid to turn them away from your table if you get a bad vibe\n\nMost people will ask the same kind of questions. Be prepared for lots and lots of general readings, love and relationship readings, and work or finance related readings. You might get the occasional health related reading. And then there will always be the one really unexpected question that might throw you for a loop\n\nThat said, most people will also only buy the shortest amount of time, so keep a lot of quick and easy spreads on hand. But some people will, at the last minute, ask for a second more in depth reading on what they really wanted to ask. So don't be surprised if you spend most of their time slot on a \"general\" reading, only for them to ask for a reading on a very complicated situation when there's only two minutes left.\n\nDepending on what comes up during a reading, intense feelings might be involved. Have tissues ready to offer the client \n\nIf you have any preferred grounding techniques, I'd recommend doing them between clients or whenever you get a lull so you can clear and refocus your mind and emotions\n\nAnd lastly, remember to have fun!!", "time": "2023-03-25 06:00:14"}, "thrice18": {"comment": "Rolling off the alpine loop is a yearly event for jeeps.", "time": "2023-03-25 05:36:11"}}, "asyncio": {"Famberlight": {"comment": "Im on windows 10. Lama 8b 4bit without lora runs fine. Here is error\n\n    C:\\Users\\olegt\\miniconda3\\envs\\textgen\\lib\\site-packages\\bitsandbytes\\cuda_setup\\main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {WindowsPath('C')}\n    warn(msg)\n    C:\\Users\\olegt\\miniconda3\\envs\\textgen\\lib\\site-packages\\bitsandbytes\\cuda_setup\\main.py:136: UserWarning: C:\\Users\\olegt\\miniconda3\\envs\\textgen did not contain libcudart.so as expected! Searching further paths...\n    warn(msg)\n    CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching /usr/local/cuda/lib64...\n    C:\\Users\\olegt\\miniconda3\\envs\\textgen\\lib\\site-packages\\bitsandbytes\\cuda_setup\\main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {WindowsPath('/usr/local/cuda/lib64')}\n    warn(msg)\n    CUDA SETUP: WARNING! libcuda.so not found! Do you have a CUDA driver installed? If you are on a cluster, make sure you are on a CUDA machine!\n    C:\\Users\\olegt\\miniconda3\\envs\\textgen\\lib\\site-packages\\bitsandbytes\\cuda_setup\\main.py:136: UserWarning: WARNING: No libcudart.so found! Install CUDA or the cudatoolkit package (anaconda)!\n    warn(msg)\n    C:\\Users\\olegt\\miniconda3\\envs\\textgen\\lib\\site-packages\\bitsandbytes\\cuda_setup\\main.py:136: UserWarning: WARNING: No GPU detected! Check your CUDA paths. Proceeding to load CPU-only library...\n    warn(msg)\n    CUDA SETUP: Loading binary C:\\Users\\olegt\\miniconda3\\envs\\textgen\\lib\\site-packages\\bitsandbytes\\libbitsandbytes_cpu.so...\n    argument of type 'WindowsPath' is not iterable\n    CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching /usr/local/cuda/lib64...\n    CUDA SETUP: WARNING! libcuda.so not found! Do you have a CUDA driver installed? If you are on a cluster, make sure you are on a CUDA machine!\n    CUDA SETUP: Loading binary C:\\Users\\olegt\\miniconda3\\envs\\textgen\\lib\\site-packages\\bitsandbytes\\libbitsandbytes_cpu.so...\n    argument of type 'WindowsPath' is not iterable\n    CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching /usr/local/cuda/lib64...\n    CUDA SETUP: WARNING! libcuda.so not found! Do you have a CUDA driver installed? If you are on a cluster, make sure you are on a CUDA machine!\n    CUDA SETUP: Loading binary C:\\Users\\olegt\\miniconda3\\envs\\textgen\\lib\\site-packages\\bitsandbytes\\libbitsandbytes_cpu.so...\n    argument of type 'WindowsPath' is not iterable\n    CUDA SETUP: Problem: The main issue seems to be that the main CUDA library was not detected.\n    CUDA SETUP: Solution 1): Your paths are probably not up-to-date. You can update them via: sudo ldconfig.\n    CUDA SETUP: Solution 2): If you do not have sudo rights, you can do the following:\n    CUDA SETUP: Solution 2a): Find the cuda library via: find / -name libcuda.so 2&gt;/dev/null\n    CUDA SETUP: Solution 2b): Once the library is found add it to the LD_LIBRARY_PATH: export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:FOUND_PATH_FROM_2a\n    CUDA SETUP: Solution 2c): For a permanent solution add the export from 2b into your .bashrc file, located at ~/.bashrc\n    Traceback (most recent call last):\n    File \"C:\\Users\\olegt\\miniconda3\\envs\\textgen\\lib\\site-packages\\gradio\\routes.py\", line 374, in run_predict\n    output = await app.get_blocks().process_api(\n    File \"C:\\Users\\olegt\\miniconda3\\envs\\textgen\\lib\\site-packages\\gradio\\blocks.py\", line 1017, in process_api\n    result = await self.call_function(\n    File \"C:\\Users\\olegt\\miniconda3\\envs\\textgen\\lib\\site-packages\\gradio\\blocks.py\", line 835, in call_function\n    prediction = await anyio.to_thread.run_sync(\n    File \"C:\\Users\\olegt\\miniconda3\\envs\\textgen\\lib\\site-packages\\anyio\\to_thread.py\", line 31, in run_sync\n    return await get_asynclib().run_sync_in_worker_thread(\n    File \"C:\\Users\\olegt\\miniconda3\\envs\\textgen\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 937, in run_sync_in_worker_thread\n    return await future\n    File \"C:\\Users\\olegt\\miniconda3\\envs\\textgen\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 867, in run\n    result = context.run(func, *args)\n    File \"C:\\Stable_Diffusion\\text-generation-webui\\server.py\", line 73, in load_lora_wrapper\n    add_lora_to_model(selected_lora)\n    File \"C:\\Stable_Diffusion\\text-generation-webui\\modules\\LoRA.py\", line 9, in add_lora_to_model\n    from peft import PeftModel\n    File \"C:\\Users\\olegt\\miniconda3\\envs\\textgen\\lib\\site-packages\\peft\\__init__.py\", line 22, in &lt;module&gt;\n    from .mapping import MODEL_TYPE_TO_PEFT_MODEL_MAPPING, PEFT_TYPE_TO_CONFIG_MAPPING, get_peft_config, get_peft_model\n    File \"C:\\Users\\olegt\\miniconda3\\envs\\textgen\\lib\\site-packages\\peft\\mapping.py\", line 16, in &lt;module&gt;\n    from .peft_model import (\n    File \"C:\\Users\\olegt\\miniconda3\\envs\\textgen\\lib\\site-packages\\peft\\peft_model.py\", line 31, in &lt;module&gt;\n    from .tuners import LoraModel, PrefixEncoder, PromptEmbedding, PromptEncoder\n    File \"C:\\Users\\olegt\\miniconda3\\envs\\textgen\\lib\\site-packages\\peft\\tuners\\__init__.py\", line 20, in &lt;module&gt;\n    from .lora import LoraConfig, LoraModel\n    File \"C:\\Users\\olegt\\miniconda3\\envs\\textgen\\lib\\site-packages\\peft\\tuners\\lora.py\", line 36, in &lt;module&gt;\n    import bitsandbytes as bnb\n    File \"C:\\Users\\olegt\\miniconda3\\envs\\textgen\\lib\\site-packages\\bitsandbytes\\__init__.py\", line 7, in &lt;module&gt;\n    from .autograd._functions import (\n    File \"C:\\Users\\olegt\\miniconda3\\envs\\textgen\\lib\\site-packages\\bitsandbytes\\autograd\\__init__.py\", line 1, in &lt;module&gt;\n    from ._functions import undo_layout, get_inverse_transform_indices\n    File \"C:\\Users\\olegt\\miniconda3\\envs\\textgen\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py\", line 9, in &lt;module&gt;\n    import bitsandbytes.functional as F\n    File \"C:\\Users\\olegt\\miniconda3\\envs\\textgen\\lib\\site-packages\\bitsandbytes\\functional.py\", line 17, in &lt;module&gt;\n    from .cextension import COMPILED_WITH_CUDA, lib\n    File \"C:\\Users\\olegt\\miniconda3\\envs\\textgen\\lib\\site-packages\\bitsandbytes\\cextension.py\", line 22, in &lt;module&gt;\n    raise RuntimeError('''\n    RuntimeError:\n    CUDA Setup failed despite GPU being available. Inspect the CUDA SETUP outputs above to fix your environment!\n    If you cannot find any issues and suspect a bug, please open an issue with detals about your environment:\n    https://github.com/TimDettmers/bitsandbytes/issues", "time": "2023-03-25 08:29:17"}, "TheRealDarkArc": {"comment": "https://docs.python.org/3.9/library/asyncio-task.html?highlight=to_thread#asyncio.to_thread\n\nIt's actually easier than that \ud83d\ude42", "time": "2023-03-25 04:34:10"}, "yvrelna": {"comment": "To those who are too thick to get it, the hint is is the name, it's called asyncio, not asynccompute.\n\nMost computationally bound tasks can be converted to IO-bound tasks though, by just running the work on a Thread/ProcessPoolExecutor.", "time": "2023-03-25 04:04:29"}}, "algorithms and data structures": {"ControversyOverflow": {"comment": "Hi, I had Data Structures and Algorithms in my degree plan as well (switched to Software Dev degree plan for a bit) and it was much harder by far. In terms of classes in the BSIT path though, I do think this was the hardest due to the sheer breadth of information you need to take in.", "time": "2023-03-25 05:44:42"}, "CashCarti1017": {"comment": "Did they hire you without C++ experience? Is it just object oriented questions or data structures and algorithms too?", "time": "2023-03-25 03:54:01"}, "425trafficeng": {"comment": "How hard are you willing to grind? Start with learning the basics of python, move onto to OOP, then data structures/algorithms and from there pick goal and research/start working towards it. If you hate your initial path you pick, backtrack and try something else. There\u2019s a ton of trial and error involved.\n\nIt\u2019s a wild tech market, you\u2019re looking at about 12-18 months before career changers have a chance barring some exceptional luck.", "time": "2023-03-25 02:53:32"}, "lardicus99": {"comment": "Here\u2019s the thing about a CS degree. Typically in an intro course you will learn the basics of a programming language such as Python that you could do on your own without too much trouble. Even another more difficult language like C++ shouldn\u2019t be out of your capabilities with a good tutorial series and practice. However what a degree really tries to cover is what programming is from a fundamental sense. You will in detail cover the structure of languages, operating systems, and networks used to communicate information. \n\nSome of this is theoretical and some of it is very practical. You will dig deep into algorithms used in programming languages and data structures used to store different pieces of information. Then you will have the opportunity to gain education in areas such as machine learning, cyber security, or embedded systems to name a few. Programming languages themselves are really just a means of communication with a computer. You can know a language without really knowing much about computer science. For a lot of CS jobs, you need a deep understanding than just how to program.\n\nThis is NOT to say you can\u2019t do this without a degree! However imo it\u2019s in the same way that you don\u2019t need a degree to learn electrical engineering (minus the access to expensive equipment). \n\nWhat I find useful in a CS degree is the knowledge you learn about programming applications and the common techniques used across different languages for solving challenging problems on a computer. \n\nI\u2019d recommend looking a little further into what a computer science program teaches you, since it is a very long path for simply learning a language (which to answer your question they will guide you through from the very basics to the end in class).", "time": "2023-03-25 02:42:20"}, "CountyExotic": {"comment": "Data structures and algorithms, linear algebra, and discrete mathematics, digital image processing/computer vision IMO", "time": "2023-03-25 00:35:43"}}, "global interpreter lock": {"Conscious-Ball8373": {"comment": "In a way, yes - so long as someone has written those specific routines in C first. But there are still costs, eg calls to C code typically hold the Global Interpreter Lock and so prevent other threads from running. It can often be worked around but it becomes arcane very quickly - and since non-arcane-ness is one of Python's big selling points, you might as well ditch python at that point.", "time": "2023-03-22 12:38:14"}, "Kered13": {"comment": "The thing is that Python has a thing called the Global Interpreter Lock, which basically means that only a single thread can actually be executing Python code at a time. Multiple threads can be useful if most of the threads are going to be idle (blocked by IO for example), or are going to be busy in non-Python code (numpy and other libraries written in C/C++/Fortran).\n\nMulti-processing works around this because each process has it's own Python interpreter, but having multiple processes uses more memory and communication between the processes is more complicated and slower. But you actually get true parallelism.\n\nIn the first case where you are blocked on IO or something similar, you can also use asynchronous code, which is another form of concurrency where multiple coroutines share a single thread.", "time": "2023-03-21 19:09:23"}, "sersherz": {"comment": "The decorators and type validation are needed because Python has expanded to so many different things. Data pipelines and APIs should have really strict definitions of what can be passed through. I think these changes are in Python's philosophy. Look at the standard libraries. Multiprocessing allows you to overcome the global interpreter lock (GIL). The language was designed with GIL but also has workarounds.\n\nI feel decorators were really needed with more complicated functions added. Rather than running python as a script or stateful OOP program, it can now have stateless API calls and perform a procedure as it is called, rather than worrying about garbage collection and handling resources explicitly.\n\nI definitely agree that Python is simple to learn but extremely difficult to master given how vast it is and how much complexity there is to the language. I think this is often lost on people who hate the language and don't fully understand just how deep it goes.", "time": "2023-03-20 22:49:48"}, "StewedAngelSkins": {"comment": "fwiw you can't run python scripts in parallel with eachother due to global interpreter lock.", "time": "2023-03-19 14:02:47"}, "carrotlordofjapan": {"comment": "Python is slower across the board than say C, but different versions of python may suffer more or less from several factors.\n\nThe most common form of python is cpython this is an interpreted language, that means that instead of created machine code which runs directly on the processor python basically your code runs in a VM which is slow.\n\nOther versions of python like PyPy do not suffer from this because they are just in time compiled (JIT) this means that you run native assembly which makes PyPy around 8-10x faster iirc.\n\nHowever all python code suffers in speed because it has features which make programming intuitive such as garbage collection. Python deals with memory management for you, but that means it doesn't always make the optimal decisions.  Python has a global interpreter lock (GIL) which largely makes multithreading ineffective in native python. Many other features like this all amount to python being extremely slow compared to C. Luckily 1. Most code doesn't actually need to be optimized very much because processors are so fast, and 2. If need be just write the performance heavy code in C then call your C code directly from python, this is how math libraries like NumPy work.", "time": "2023-03-18 02:20:19"}}}